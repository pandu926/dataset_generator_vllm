# ğŸš€ UNSIQ Synthetic Dataset Pipeline

> **START HERE (PENTING):**
> Sebelum menjalankan kode, **WAJIB** membaca dokumen di folder `docs/` untuk memahami strategi dan tujuan project ini.

## ğŸ“– Must-Read Documentation

Jika Anda baru di project ini, buka file berikut secara berurutan:

1.  **`docs/PROJECT_BLUEPRINT.md`** (ğŸ‘‘ Master Plan): Menjelaskan visi, arsitektur, dan standar kualitas dataset yang kita bangun.
2.  **`docs/synthetic_data_strategy.md`**: Detail teknis tentang strategi "Anti-Forgetting", Persona, dan Complexity Tiers.

---

## ğŸ—ï¸ Project Structure

File dan folder dalam project ini telah diatur dengan standar _Python Project_ sebagai berikut:

```text
pipeline-dataset-generator/
â”‚
â”œâ”€â”€ ğŸ“‚ docs/               # ğŸ§  OTAK PROJECT (Dokumentasi & Strategi)
â”‚   â”œâ”€â”€ PROJECT_BLUEPRINT.md      # Master Plan
â”‚   â””â”€â”€ synthetic_data_strategy.md # Strategi Detail
â”‚
â”œâ”€â”€ ğŸ“‚ data/               # ğŸ—„ï¸ GUDANG DATA
â”‚   â”œâ”€â”€ seeds/             # Input: File JSON lama (dataset_biaya.json, dll)
â”‚   â”œâ”€â”€ rag_source/        # Input: Dokumen PDF/MD sumber kebenaran (RAG)
â”‚   â”œâ”€â”€ chunks/            # Process: Hasil potongan RAG siap pakai
â”‚   â””â”€â”€ output/            # Result: Dataset final hasil generate
â”‚
â”œâ”€â”€ ğŸ“‚ src/                # âš™ï¸ MESIN (Source Code)
â”‚   â”œâ”€â”€ llm_multiturn_generator.py # Logic utama generator (Persona, CoT)
â”‚   â”œâ”€â”€ vllm_engine.py             # Driver untuk koneksi ke Model LLM
â”‚   â”œâ”€â”€ phase1_preparation.py      # Script pembuat Chunks RAG
â”‚   â””â”€â”€ e5_embedding.py            # Script embedding search
â”‚
â”œâ”€â”€ ğŸ“‚ config/             # ğŸ› ï¸ PENGATURAN
â”‚   â””â”€â”€ config.yaml        # Konfigurasi path, model, dan prompt
â”‚
â”œâ”€â”€ main.py                # â–¶ï¸ TOMBOL START (Script Eksekusi Utama)
â””â”€â”€ requirements.txt       # Daftar library python
```

---

## ğŸ¯ Project Goal

Tujuan project ini adalah men-transformasi data tanya-jawab pendek (Single-turn) menjadi percakapan panjang yang cerdas (Multi-turn) untuk melatih model AI (Fine-tuning Gemma-3-1B).

**Output yang diharapkan:**
1.000 Percakapan JSONL yang memiliki:

- **Reasoning**: Bot berpikir sebelum menjawab.
- **Persona**: Bot memiliki karakter (bukan robot kaku).
- **Clarification**: Bot bertanya balik jika user tidak jelas.

---

## ğŸš€ How to Run

1.  Pastikan semua library terinstall.
2.  Siapkan seed data di `data/seeds/`.
3.  Jalankan perintah:
    ```bash
    python main.py
    ```

---

_Dibuat oleh Tim Agentic Coding untuk Project UNSIQ Fine-tuning._
